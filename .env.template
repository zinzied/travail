# AI Model API Configuration
# Copy this file to .env and add your API keys

# =============================================================================
# RECOMMENDED: Groq API (Fast & Free)
# =============================================================================
# Get your free API key from: https://console.groq.com
# Models: Llama 3, Mixtral, Gemma
# Speed: Ultra-fast (< 1 second)
# Cost: Free with generous limits
GROQ_API_KEY=

# =============================================================================
# OpenAI API (Premium)
# =============================================================================
# Get API key from: https://platform.openai.com
# Models: GPT-4, GPT-3.5-turbo
# Speed: Fast
# Cost: Pay per use
OPENAI_API_KEY=

# =============================================================================
# Anthropic Claude API
# =============================================================================
# Get API key from: https://console.anthropic.com
# Models: Claude 3 (Opus, Sonnet, Haiku)
# Speed: Fast
# Cost: Pay per use
ANTHROPIC_API_KEY=

# =============================================================================
# Google Gemini API
# =============================================================================
# Get API key from: https://makersuite.google.com
# Models: Gemini Pro
# Speed: Fast
# Cost: Free tier available
GOOGLE_API_KEY=

# =============================================================================
# Cohere API
# =============================================================================
# Get API key from: https://dashboard.cohere.ai
# Models: Command, Command Light
# Speed: Fast
# Cost: Free tier available
COHERE_API_KEY=

# =============================================================================
# Hugging Face API
# =============================================================================
# Get API token from: https://huggingface.co/settings/tokens
# Models: Llama 2, Mistral, CodeLlama
# Speed: Medium
# Cost: Free tier available
HUGGINGFACE_API_KEY=

# =============================================================================
# Local/Self-Hosted APIs
# =============================================================================

# Ollama (Local AI models)
# Download from: https://ollama.ai
# No API key needed, just install and run: ollama serve
OLLAMA_BASE_URL=http://localhost:11434

# LocalAI (Self-hosted OpenAI compatible)
# Setup: https://localai.io
LOCALAI_BASE_URL=http://localhost:8080
LOCALAI_API_KEY=

# LM Studio (Local model runner)
# Download from: https://lmstudio.ai
LMSTUDIO_BASE_URL=http://localhost:1234

# Text Generation WebUI
# Setup: https://github.com/oobabooga/text-generation-webui
TEXTGEN_WEBUI_BASE_URL=http://localhost:5000

# =============================================================================
# Application Settings
# =============================================================================

# Default language (en, fr, ar)
DEFAULT_LANGUAGE=en

# Default AI provider (groq, openai, anthropic, google, ollama, etc.)
DEFAULT_AI_PROVIDER=groq

# Maximum tokens for AI responses
MAX_TOKENS=2000

# Temperature for AI responses (0.0 to 1.0)
AI_TEMPERATURE=0.7

# Enable debug logging
DEBUG=false

# =============================================================================
# File Processing Settings
# =============================================================================

# Maximum file size in MB
MAX_FILE_SIZE_MB=10

# Temporary directory for file processing
TEMP_DIR=temp/

# =============================================================================
# Web Application Settings
# =============================================================================

# Streamlit server settings
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost

# Enable/disable features
ENABLE_BATCH_PROCESSING=true
ENABLE_EXCEL_INTEGRATION=true
ENABLE_AI_CHAT=true

# =============================================================================
# Security Settings
# =============================================================================

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Session timeout (minutes)
SESSION_TIMEOUT_MINUTES=30

# =============================================================================
# QUICK SETUP GUIDE
# =============================================================================

# For fastest setup (recommended):
# 1. Get Groq API key: https://console.groq.com
# 2. Set GROQ_API_KEY=your_key_here
# 3. Save this file as .env
# 4. Restart the application

# For local/private setup:
# 1. Download Ollama: https://ollama.ai
# 2. Run: ollama pull llama3
# 3. Run: ollama serve
# 4. No API key needed!

# For premium features:
# 1. Get OpenAI API key: https://platform.openai.com
# 2. Set OPENAI_API_KEY=your_key_here
# 3. Save this file as .env
# 4. Restart the application
